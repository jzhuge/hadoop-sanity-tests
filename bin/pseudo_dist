#!/usr/bin/env bash

mydir=$(dirname $0)
myname=$(basename $0)

export HADOOP_HOME=$(detect_hadoop_home)
export HADOOP_CONF_DIR=${HADOOP_CONF_DIR:-$HADOOP_HOME/etc/hadoop}
export HADOOP_KEYSTORE_PASSWORD=${HADOOP_KEYSTORE_PASSWORD:-password}
export HADOOP_LOGLEVEL=${HADOOP_LOGLEVEL:-WARN}

: ${TEST_HADOOP_DFS_DIR:=/tmp/hadoop-$USER/dfs}
: ${TEST_SERVICES:=hdfs yarn balancer httpfs kms}
: ${TEST_SILENT:=true}

if [[ $TEST_SILENT = false ]]; then
  export HTTPFS_SILENT=${HTTPFS_SILENT:-false}
  export KMS_SILENT=${KMS_SILENT:-false}
else
  export HTTPFS_SILENT=${HTTPFS_SILENT:-true}
  export KMS_SILENT=${KMS_SILENT:-true}
fi

PATH=$HADOOP_HOME/sbin:$HADOOP_HOME/bin:$PATH

usage() {
  cat <<EOF
SYNOPSIS
  $myname start [<conf>]
  $myname restart [<conf>]
  $myname kill|stop
  $myname envvars
EOF
}

print_env_vars() {
  cat <<EOF
PATH=$PATH
EOF
}

pseudo_dist_mode() {
  local action=$1
  local start_hdfs
  local start_yarn
  local start_httpfs
  local start_kms

  for svc in ${TEST_SERVICES}; do
    case $svc in
      hdfs)
        start_hdfs=yes
        ;;
      yarn)
        start_yarn=yes
        ;;
      balancer)
        start_hdfs=yes
        start_balancer=yes
        ;;
      httpfs)
        start_hdfs=yes
        start_httpfs=yes
        ;;
      kms)
        start_kms=yes
        ;;
      *)
        echo "Unknown service '$svc'" >&2
        exit 1
    esac
  done
 
  set -x

  if [[ start == $action ]]; then
    [[ -r $HADOOP_CONF_DIR/test_env ]] && . $HADOOP_CONF_DIR/test_env

    # For old httpfs.sh
    if [[ $TEST_SSL_ENABLED == yes ]]; then
      local httpfs_opts="-config conf/ssl-server.xml"
    fi

    # For old kms.sh
    if [[ $TEST_SSL_ENABLED == yes ]]; then
      local kms_opts="-config conf/ssl-server.xml"
    fi
  fi

  if [[ -n $start_hdfs ]]; then
    if [[ start == $action ]]; then
      echo "Removing directory $TEST_HADOOP_DFS_DIR"
      rm -fr $TEST_HADOOP_DFS_DIR
      hdfs namenode -format
    fi
    $action-dfs.sh
    if [[ start == $action ]]; then
      hdfs dfs -mkdir -p /tmp &&
      hdfs dfs -chmod 1777 /tmp
      hdfs dfs -mkdir -p /user/$USER &&
      hdfs dfs -chown $USER /user/$USER
    fi
  fi

  [[ -n $start_yarn ]] && $action-yarn.sh
  [[ -n $start_balancer ]] && $action-balancer.sh
  [[ -n $start_httpfs ]] && httpfs.sh $action $httpfs_opts
  [[ -n $start_kms ]] && kms.sh $action $kms_opts
}

copy_conf() {
  conf=$1
  if [[ -z $conf ]]; then
    echo "Not changing configuration"
    return
  fi
  if [[ ! -d $conf ]]; then
    echo "The new config dir '$conf' does not exist" >&2
    exit
  fi
  if [[ ! -d $HADOOP_CONF_DIR ]]; then
    echo "The Hadoop config dir '$HADOOP_CONF_DIR' does not exist" >&2
    exit
  fi
  if [[ -d $HADOOP_CONF_DIR.original ]]; then
    echo "Restoring $HADOOP_CONF_DIR from $HADOOP_CONF_DIR.original"
    rm -fr $HADOOP_CONF_DIR
    cp -a $HADOOP_CONF_DIR.original $HADOOP_CONF_DIR
  else
    echo "Saving $HADOOP_CONF_DIR to $HADOOP_CONF_DIR.original"
    cp -a $HADOOP_CONF_DIR $HADOOP_CONF_DIR.original
  fi
  echo "Copying $conf to $HADOOP_CONF_DIR"
  cp $conf/* $HADOOP_CONF_DIR
}

if (( $# == 0 )); then
  usage
  exit
fi

while (( $# > 0 )); do
  case $1 in
    -h|--help)
      usage
      exit
      ;;
    envvars)
      print_env_vars
      ;;
    kill|stop)
      pseudo_dist_mode stop
      jps
      ;;
    restart)
      pseudo_dist_mode stop
      copy_conf "$2"
      pseudo_dist_mode start
      jps
      shift # past argument
      ;;
    start)
      copy_conf "$2"
      pseudo_dist_mode start
      jps
      shift # past argument
      ;;
    -*)
      echo "Unknown option '$1'" >&2
      exit 1
      ;;
    *)
      echo "Unknown sub-command '$1'" >&2
      exit 1
      break
  esac
  shift
done
